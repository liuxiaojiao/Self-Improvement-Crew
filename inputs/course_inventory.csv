Title,Category,URL,Level,Length,Instructor,Highlights,Content,Syllabus,Audience,Skills
Machine Learning in Production,Course,https://www.deeplearning.ai/courses/machine-learning-in-production/,Intermediate,1 month (5 hours/week),Andrew Ng,"Design an ML production system end-to-end: project scoping, data needs, modeling strategies, and deployment requirements. Establish a model baseline, address concept drift, and prototype how to develop, deploy, and continuously improve a productionized ML application.","Machine learning engineering for production refers to the tools, techniques, and practical experiences that transform theoretical ML knowledge into a production-ready skillset. The Machine Learning in Production course covers how to conceptualize integrated systems that continuously operate in production as well as solve common challenges unique to the production environment. In striking contrast with standard machine learning modeling, production systems need to handle relentlessly evolving data. Moreover, the production system must run non-stop at the minimum cost while producing the maximum performance. In this Machine Learning in Production course, you will build intuition about designing a production ML system end-to-end: project scoping, data needs, modeling strategies, and deployment patterns and technologies. You will learn strategies for addressing common challenges in production like establishing a model baseline, addressing concept drift, and performing error analysis. You’ll follow a framework for developing, deploying, and continuously improving a productionized ML application. Understanding machine learning and deep learning concepts is essential, but if you’re looking to build an effective AI career, you need experience preparing your projects for deployment as well. Machine learning engineering for production combines the foundational concepts of machine learning with the skills and best practices of modern software development necessary to successfully deploy and maintain ML systems in real-world environments.","Week 1 (3 Hours): Overview of the ML Lifecycle and Deployment - Identify the key components of the ML project lifecycle and pipeline and select the best deployment and monitoring patterns for different production scenarios. Week 2 (3 Houros): Selecting and Training a Model - Optimize model performance and metrics by prioritizing disproportionately important examples that represent key slices of a dataset. Week 3 (4 Hours): Data Definition and Baseline - Solve production challenges specific to structured, unstructured, small, and big data. Understand why label consistency is essential and how you can improve it.","This course is designed for individuals looking to build a career in AI, specifically in the areas of machine learning engineering and production.","Data Pipiles, Model Pipelines, Deployment Pipelines, Managing Machine Learning Production systems, ML Deployment Challenges, Project Scoping and Design, Concept Drift, Model Baseline, Human-level Performance (HLP), Data transformation, Data augmentation, Data validation, Model Performance Analysis, Machine Learning Engineering for Production"
Generative AI for Everyone,Course,https://www.deeplearning.ai/courses/generative-ai-for-everyone/,Introductory,3 Hours,Andrew Ng,"Learn directly from Andrew Ng about the technology of generative AI, how it works, and what it can (and can’t) do. Get an overview of AI tools, and learn from real-world examples of generative AI in use today. Understand the impacts of generative AI on business and society to develop effective AI strategies and approaches.","Generative AI for Everyone offers his unique perspective on empowering you and your work with generative AI. Andrew will guide you through how generative AI works and what it can (and can’t) do. It includes hands-on exercises where you’ll learn to use generative AI to help in day-to-day work and receive tips on effective prompt engineering, as well as learning how to go beyond prompting for more advanced uses of AI. You’ll delve into real-world applications and learn common use cases, and get hands-on time with generative AI tools to put your knowledge into action, and gain insight into AI’s impact on both business and society. This course was created to ensure everyone can be a participant in our AI-powered future.","By the end of this course, you will learn What is generative AI, What it can and cannot do, How to use it in your own world/business, Debunking misinformation about generative AI and thinking through how to use this technology best. Learning best practices for learning and exploring whether or not genAI would be useful. Week 1 (1 Hour): Define Generative AI and illustrate how insights derived from supervised learning have enhanced our comprehension of Generative AI. Identify the limitations and boundaries of Generative AI and apply practical techniques and strategies for creating prompts that enhance the quality and relevance of large language models (LLMs) responses. List common use cases for Generative AI with writing, reading, and chatting tasks on web-based and software-based interfaces. Week 2 (2 Hours): Generative AI Projects: identify and build generative AI use cases and technology options. Week 3 (1 Hour): Impact on business and society , how teams can take advantage of Generative AI, AI risks and responsible AI. ","This course is for anyone who’s interested in learning about the uses, impacts, and underlying technologies of generative AI, today and in the future. It doesn’t require any coding skills or prior knowledge of AI.","Generative AI Tools, AI Strategy for Work and Business, How Generative AI Works, AI Productivity, AI Beyond Prompting"
Generative AI with LLMs,Course,https://www.deeplearning.ai/courses/generative-ai-with-llms/,Intermediate,15 Hours,"Antje Barth, Chris Fregly, Shelbee Eigenbrode, Mike Chambers","Gain foundational knowledge, practical skills, and a functional understanding of how generative AI works. Dive into the latest research on Gen AI to understand how companies are creating value with cutting-edge technology. Instruction from expert AWS AI practitioners who actively build and deploy AI in business use-cases today.","Deeply understand generative AI, describing the key steps in a typical LLM-based generative AI lifecycle, from data gathering and model selection, to performance evaluation and deployment. Describe in detail the transformer architecture that powers LLMs, how they’re trained, and how fine-tuning enables LLMs to be adapted to a variety of specific use cases. Use empirical scaling laws to optimize the model’s objective function across dataset size, compute budget, and nference requirements. Apply state-of-the art training, tuning, inference, tools, and deployment methods to maximize the performance of models within the specific constraints of your project. Discuss the challenges and opportunities that generative AI creates for businesses after hearing stories from industry researchers and practitioners. ","Week 1 (5 Hours): Generative AI use cases, project lifecycle, and model pre-training. Week 2 (4 Hours): Fine-tuning and evaluating large language models. Week 3 (6 Hours): Reinforcement learning and LLM-powered applications","Data scientists, machine learning engineers, prompt engineers, research engineers, and anyone interested in developing with generative AI.","Generative AI, transformer architecture, model training, fine-tuning, optimization, deployment."
AI for Everyone,Course,https://www.deeplearning.ai/courses/ai-for-everyone/,Introductory,6 hours,Andrew Ng,"AI is not only for engineers. If you want your organization to become better at using AI, this is the course to tell everyone – especially your non-technical colleagues – to take.","AI is not only for engineers. “AI for Everyone”, a non-technical course, will help you understand AI technologies and spot opportunities to apply AI to problems in your own organization. You will see examples of what today’s AI can – and cannot – do. Finally, you will understand how AI is impacting society and how to navigate through this technological change. If you are a non-technical business professional, “AI for Everyone” will help you understand how to build a sustainable AI strategy. If you are a machine learning engineer or data scientist, this is the course to ask your manager, VP or CEO to take if you want them to understand what you can (and cannot!) do.","Week 1 (1 Hour): What is AI
Introduction, Machine Learning, What is data, The terminology of AI, What makes an AI company? What Machine Learning can and cannot do, Intuitive explanation of deep learning
Week 2 (1 Hour): Building AI Projects
Workflow of a Machine Learning project, Workflow of a Data Science project, Every job function needs to learn to use data, How to choose an AI project, Working with an AI team, Technical tools for AI teams
Week 3 (2 Hours): AI in your company
Case study: Smart speaker, Case study: Self-driving car, Example roles of an AI team, AI Transformation Playbook, AI pitfalls to avoid, Taking your first step in AI, Survey of major AI applications, Survey of major AI techniques
Week 4 (1 Hour): AI and Society
A realistic view of AI, Discrimination / Bias, Adversarial attacks, Adverse uses, AI and developing nations, AI and jobs, Conclusion","Non-technical business professionals, machine learning engineers, data scientists","Workflow of Machine Learning Projects, AI Terminology, AI Strategy, Workflow of Data Science Projects"
Multi AI Agent Systems with crewAI,Short Course,https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/,Beginner,1 Hour,João Moura,"Exceed the performance of prompting a single LLM by designing and prompting a team of AI agents through natural language. Use an open source library, crewAI, to automate repeatable, multi-step tasks like tailoring a resume to a job description; and automate business processes that are typically done by a group of people, like event planning. By creating a team of AI agents, you can define a specific role, goal, and backstory for each agent, which breaks down complex multi-step tasks and assigns them to agents that are customized to perform those tasks.","Learn key principles of designing effective AI agents, and organizing a team of AI agents to perform complex, multi-step tasks. Apply these concepts to automate 6 common business processes. Role-playing: Assign specialized roles to agents. Memory: Provide agents with short-term, long-term, and shared memory. Tools: Assign pre-built and custom tools to each agent (e.g. for web search). Focus: Break down the tasks, goals, and tools and assign to multiple AI agents for better performance. Guardrails: Effectively handle errors, hallucinations, and infinite loops. Cooperation: Perform tasks in series, in parallel, and hierarchically. Throughout the course, you’ll work with crewAI, an open source library designed for building multi-agent systems. You’ll learn to build agent crews that execute common business processes, such as: Tailor resumes and interview prep for job applications. Research, write and edit technical articles. Automate customer support inquiries. Conduct customer outreach campaigns. Plan and execute events. Perform financial analysis. By the end of the course, you will have designed several multi-agent systems to assist you in common business processes, and also studied the key principles of AI agent systems.",,"If you’ve taken some prompt engineering courses, have some familiarity with basic coding, and want to incorporate LLMs in your professional init our professional work, then this course is designed for you!","Designing effective AI agents, Organizing a team of AI agents, Automation of business processes, Role-playing, Memory management, Tool assignment, Task breakdown, Error handling, Cooperation strategies"
Building Your Own Database Agent,Short Course,https://www.deeplearning.ai/short-courses/building-your-own-database-agent/,Beginner,1 Hour,Adrian Gonzalez Sanchez,"Interact with tabular data and SQL databases using natural language, enabling more efficient and accessible data analysis. Gain hands-on experience with the Azure OpenAI Service, implementing techniques like Retrieval Augmented Generation (RAG) and function calling. Use Azure OpenAI Service’s Assistants API, and test it with function calling and code interpreter features.","In Building Your Own Database Agent you will develop an AI agent that interacts with databases using natural language, simplifying the process for querying and extracting insights. Created in partnership with Microsoft and taught by Adrian Gonzalez Sanchez, Data and AI Specialist at Microsoft, this course is designed for developers, data professionals, as well as business analysts and professionals who want more sophisticated interaction with their databases through natural language instead of advanced SQL queries.
What you’ll do in this course: Learn about the levels of knowledge customization with Azure OpenAI Service, focusing on RAG to build your first AI agent, deploy your Azure OpenAI Service instance, test the API, and set up an orchestration engine like LangChain to enable these scenarios. Load tabular data from a CSV file and perform natural language queries using the Azure OpenAI service to extract information quickly. Learn to reapply the agent to analyze your own CSV files. Implement LangChain agents to connect to a provided SQL database, and how to build a DB agent that translates natural language to SQL code. Use Azure OpenAI Service’s function calling feature to use pre-built functions for sending queries to databases, improving the efficiency and security of your SQL agent. Work with the Assistants API and test it with the function calling and code interpreter features, which will enable you to connect to SQL databases and create your own DB agents more efficiently. By the end of the course, you’ll be equipped with the technical knowledge and practical experience to implement similar systems in your own projects or organizations, enabling more efficient and accessible data interaction and analysis. ",,"If you want to learn how to interact with databases through natural language, this beginner-friendly course is for you. Familiarity with Python programming and databases (CSV files and SQL) is recommended, but not required.","Azure OpenAI Service, Retrieval Augmented Generation, LangChain, function calling, SQL code translation, Assistants API"
AI Agents in LangGraph,Short Course,https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/,Intermediate,1 Hour,"Harrison Chase, Rotem Weiss","Learn about LangGraph’s components and how they enable the development, debugging, and maintenance of AI agents. Integrate agentic search capabilities to enhance agent knowledge and performance. Learn directly from LangChain founder Harrison Chase and Tavily founder Rotem Weiss.","LangChain, a popular open source framework for building LLM applications, recently introduced LangGraph. This extension allows developers to create highly controllable agents.
In this course you will learn to build an agent from scratch using Python and an LLM, and then you will rebuild it using LangGraph, learning about  its components and how to combine them to build flow-based applications.
Additionally, you will learn about agentic search, which returns multiple answers in an agent-friendly format, enhancing the agent’s built-in knowledge. This course will show you how to use agentic search in your applications to provide better data for agents to enhance their output.

In detail:
Build an agent from scratch, and understand the division of tasks between the LLM and the code around the LLM.
Implement the agent you built using LangGraph.
Learn how agentic search retrieves multiple answers in a predictable format, unlike traditional search engines that return links.
Implement persistence in agents, enabling state management across multiple threads, conversation switching, and the ability to reload previous states.
Incorporate human-in-the-loop into agent systems.
Develop an agent for essay writing, replicating the workflow of a researcher working on this task.",,"If you have intermediate Python knowledge and want to learn how to create more controllable agents using the LangGraph open source framework, this course is for you.","LangChain, LangGraph, Python, LLM, agentic search, state management, human-in-the-loop"
Building Agentic RAG with LlamaIndex,Short Course,https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/,Beginner,1 Hour,Jerry Liu,"Learn how to build an agent that can reason over your documents and answer complex questions.
Build a router agent that can help you with Q&A and summarization tasks, and extend it to handle passing arguments to this agent.
Design a research agent that handles multi-documents and learn about different ways to debug and control this agent.","Build the simplest form of agentic RAG – a router. Given a query, the router will pick one of two query engines, Q&A or summarization, to execute a query over a single document.
Add tool calling to your router agent where you will use an LLM to not only pick a function to execute but also infer an argument to pass to the function.
Build a research assistant agent. Instead of tool calling in a single-shot setting, an agent is able to reason over tools in multiple steps.
Build a multi-document agent where you will learn how to extend the research agent to handle multiple documents.
Unlike the standard RAG pipeline—suitable for simple queries across a few documents—this intelligent approach adapts based on initial findings to enhance further data retrieval. You’ll learn to develop an autonomous research agent, enhancing your ability to engage with and analyze your data comprehensively.
You’ll practice building agents capable of intelligently navigating, summarizing, and comparing information across multiple research papers from arXiv. Additionally, you’ll learn how to debug these agents, ensuring you can guide their actions effectively.",,Anyone who has basic Python knowledge and wants to learn how to quickly build agents that can reason over their own documents.,"agentic RAG, router, query engines, LLM, multi-document agent, research agent, Python"
AI Agentic Design Patterns with AutoGen,Short Course,https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen/,Beginner,1 Hour,"Chi Wang, Qingyun Wu","Use the AutoGen framework to build multi-agent systems with diverse roles and capabilities for implementing complex AI applications. Implement agentic design patterns: Reflection, Tool use, Planning, and Multi-agent collaboration using AutoGen.","In AI Agentic Design Patterns with AutoGen you’ll learn how to build and customize multi-agent systems, enabling agents to take on different roles and collaborate to accomplish complex tasks using AutoGen, a framework that enables development of LLM applications using multi-agents. In this course you’ll create: A two-agent chat that shows a conversation between two standup comedians, using “ConversableAgent,” a built-in agent class of AutoGen for constructing multi-agent conversations. 
A sequence of chats between agents to provide a fun customer onboarding experience for a product, using the multi-agent collaboration design pattern.
A high-quality blog post by using the agent reflection framework. You’ll use the “nested chat” structure to develop a system where reviewer agents, nested within a critic agent, reflect on the blog post written by another agent.
A conversational chess game where two agent players can call a tool and make legal moves on the chessboard, by implementing the tool use design pattern.
A coding agent capable of generating the necessary code to plot stock gains for financial analysis. This agent can also integrate user-defined functions into the code.
Agents with coding capabilities to complete a financial analysis task. You’ll create two systems where agents collaborate and seek human feedback. The first system will generate code from scratch using an LLM, and the second will use user-provided code.
You can use the AutoGen framework with any model via API call or locally within your own environment. By the end of the course, you’ll have hands-on experience with AutoGen’s core components and a solid understanding of agentic design patterns. You’ll be ready to effectively implement multi-agent systems in your workflows.",,"If you have basic Python coding experience and you’re interested in automating complex workflows using AI agents, this course will provide the practical skills and knowledge you need to leverage AutoGen effectively.","AutoGen, Multi-agent systems, ConversableAgent, Nested chat, Tool use, Planning, Multi-agent collaboration"
Building Multimodal Search and RAG,Short Course,https://www.deeplearning.ai/short-courses/building-multimodal-search-and-rag/,Intermediate,1 Hour,Sebastian Witalec,"Learn how multimodality works by implementing contrastive learning, and see how it can be used to build modality-independent embeddings for seamless any-to-any retrieval..Build multimodal RAG systems that retrieve multimodal context and reason over it to generate more relevant answers. Implement industry applications of multimodal search and build multi-vector recommender systems.","LLearn how to build multimodal search and RAG systems. RAG systems enhance an LLM by incorporating proprietary data into the prompt context. Typically, RAG applications use text documents, but, what if the desired context includes multimedia like images, audio, and video? This course covers the technical aspects of implementing RAG with multimodal data to accomplish this. Learn how multimodal models are trained through contrastive learning and implement it on a real dataset.
Build any-to-any multimodal search to retrieve relevant context across different data types.
Learn how LLMs are trained to understand multimodal data through visual instruction tuning and use them on multiple image reasoning examples
Implement an end-to-end multimodal RAG system that analyzes retrieved multimodal context to generate insightful answers
Explore industry applications like visually analyzing invoices and flowcharts to output structured data.
Create a multi-vector recommender system that suggests relevant items by comparing their similarities across multiple modalities.
As AI systems increasingly need to process and reason over multiple data modalities, learning how to build such systems is an important skill for AI developers. This course equips you with the key skills to embed, retrieve, and generate across different modalities. By gaining a strong foundation in multimodal AI, you’ll be prepared to build smarter search, RAG, and recommender systems.",,"This course is for anyone who wants to start building their own multimodal applications. Basic Python knowledge, as well as familiarity with RAG is recommended to get the most out of this course.","multimodality, contrastive learning, modality-independent embeddings, multimodal search, RAG systems, multi-vector recommender systems"
Quantization in Depth,Short Course,https://www.deeplearning.ai/short-courses/quantization-in-depth/,Intermediate,1 Hour,"Marc Sun, Younes Belkada","Try out different variants of Linear Quantization, including symmetric vs. asymmetric mode, and different granularities like per tensor, per channel, and per group quantization. Build a general-purpose quantizer in Pytorch that can quantize the dense layers of any open source model for up to 4x compression on dense layers. Implement weights packing to pack four 2-bit weights into a single 8-bit integer.","In Quantization in Depth you will build model quantization methods to shrink model weights to _ their original size, and apply methods to maintain the compressed model’s performance. Your ability to quantize your models can make them more accessible, and also faster at inference time. Implement and customize linear quantization from scratch so that you can study the tradeoff between space and performance, and then build a general-purpose quantizer in PyTorch that can quantize any open source model. You’ll implement  techniques to compress model weights from 32 bits to 8 bits and even 2 bits. Join this course to: Build and customize linear quantization functions, choosing between two “modes”: asymmetric and symmetric; and three granularities: per-tensor, per-channel, and per-group quantization.
Measure the quantization error of each of these options as you balance the performance and space tradeoffs for each option.
Build your own quantizer in PyTorch, to quantize any open source model’s dense layers from 32 bits to 8 bits.
Go beyond 8 bits, and pack four 2-bit weights into one 8-bit integer.
Quantization in Depth lets you build and customize your own linear quantizer from scratch, going beyond standard open source libraries such as PyTorch and Quanto, which are covered in the short course Quantization Fundamentals, also by Hugging Face.",,"Building on the concepts introduced in Quantization Fundamentals with Hugging Face, this course will help deepen your understanding of linear quantization methods. If you’re looking to go further into quantization, this course is the perfect next step.","Linear Quantization, PyTorch, Model Compression, Performance Optimization"
Getting Started With Mistral,Short Course,https://www.deeplearning.ai/short-courses/getting-started-with-mistral/,Beginner,1 Hour,Sophia Yang,"Explore Mistral’s three open source models (Mistral 7B, Mixtral 8x7B, and the latest Mixtral 8x22B), and three commercial models (small, medium, and large), which Mistral provides access to via web interface and API calls. Leverage Mistral’s JSON mode to generate LLM responses in a structured JSON format, enabling integration of LLM outputs into larger software applications. Use Mistral’s API to call user-defined Python functions for tasks like web searches or retrieving text from databases, enhancing the LLM’s ability to find relevant information to answer user queries.","In this course, you’ll access Mistral AI’s collection of open source and commercial models, including the Mixtral 8x7B model, and the latest Mixtral 8x22B. You’ll learn about selecting the right model for your use case, and get hands-on with features like effective prompting techniques, function calling, JSON mode, and Retrieval Augmented Generation (RAG). In detail: Access and prompt Mistral models via API calls for tasks, and decide whether your task is either a simple task (classification), medium (email writing), or advanced (coding) level of complexity, and consider speed requirements to choose an appropriate model.
Learn to use Mistral’s native function calling, in which you give an LLM tools it can call as needed to perform tasks that are better performed by traditional code, such as querying a database for numerical data. 
Build a basic RAG system from scratch with similarity search, properly chunk data, create embeddings, and implement this tool as a function in your chat system.
Build a chat interface to interact with the Mistral models and ask questions about a document that you upload.
By the end of this course, you’ll be equipped to leverage Mistral AI’s leading open source and commercial models.",,"Getting Started with Mistral is a beginner-friendly course and it’s suitable for anyone who wants to learn about and use Mistral AI’s collection of advanced open source and commercial LLMs. If you have taken ChatGPT Prompt Engineering for Developers or Prompt Engineering with Llama 2, this is a great next step!","Mistral models, API calls, prompting techniques, function calling, JSON mode, Retrieval Augmented Generation (RAG), similarity search, data chunking, embeddings, chat interface development"
Knowledge Graphs for RAG,Short Course,https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/,Intermediate,1 Hour,Andreas Kollegger,"Use Neo4j’s query language Cypher to manage and retrieve data stored in knowledge graphs.
Write knowledge graph queries that find and format text data to provide more relevant context to LLMs for Retrieval Augmented Generation.
Build a question-answering system using Neo4j and LangChain to chat with a knowledge graph of structured text documents.","Knowledge graphs are used in development to structure complex data relationships, drive intelligent search functionality, and build powerful AI applications that can reason over different data types. Knowledge graphs can connect data from both structured and unstructured sources (databases, documents, etc.), providing an intuitive and flexible way to model complex, real-world scenarios.
Unlike tables or simple lists, knowledge graphs can capture the meaning and context behind the data, allowing you to uncover insights and connections that would be difficult to find with conventional databases. This rich, structured context is ideal for improving the output of large language models (LLMs), because you can build more relevant context for the model than with semantic search alone.
This course will teach you how to leverage knowledge graphs within retrieval augmented generation (RAG) applications. You’ll learn to:
Understand the basics of how knowledge graphs store data by using nodes to represent entities and edges to represent relationships between nodes.
Use Neo4j’s query language, Cypher, to retrieve information from a fun graph of movie and actor data.
Add a vector index to a knowledge graph to represent unstructured text data and find relevant texts using vector similarity search.
Build a knowledge graph of text documents from scratch, using publicly available financial and investment documents as the demo use case
Explore advanced techniques for connecting multiple knowledge graphs and using complex queries for comprehensive data retrieval.
Write advanced Cypher queries to retrieve relevant information from the graph  and format it for inclusion in your prompt to an LLM. After course completion, you’ll be well-equipped to use knowledge graphs to uncover deeper insights in your data, and enhance the performance of LLMs with structured, relevant context.",,"Anyone who wants to understand how knowledge graphs work, how to build with them, and create better RAG applications. We recommend familiarity with LangChain or taking LangChain: Chat with Your Data prior to this course.","Neo4j, Cypher, vector similarity search, knowledge graph construction, advanced query techniques"
Prompt Engineering with Llama 2 & 3,Short Course,https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/,Beginner,1 Hour,Amit Sangani,"Learn best practices specific to prompting Llama 2 & 3 models.
Interact with Meta Llama 2 Chat, Code Llama, and Llama Guard models.
See how you can build safe, responsible AI applications using the Llama Guard model.","Open up your prompt engineering to the Llama 2 & 3 collection of models! Learn best practices for prompting and building applications with these powerful open commercial license models. Interact with the Llama 2 and Llama 3 models with a simple API call, and explore the differences in output between models for a variety of tasks. What you’ll do: Learn best practices for prompting and selecting among the Llama 2 & 3 models by using them as a personal assistant to help you complete day-to-day tasks.
Experiment with advanced prompt engineering techniques, like few-shot prompting to get Llama 2 to classify the sentiment of text messages, and chain-of-thought prompting to solve logic problems.
Treat Code Llama as a pair programming partner to both learn to write and improve code.
Promote safe and responsible use of LLMs by having Llama Guard check user prompts and model responses for harmful content.
Llama 2 and Llama 3 models and model weights are free to download, including quantized model versions that can run on your local machine. Join a thriving community of open source developers that is building applications powered by Llama 2 and Llama 3.",,Anyone who is interested in learning prompt engineering and wants to try out Meta Llama 2 and Llama 3 models.,"prompt engineering, Llama models, few-shot prompting, chain-of-thought prompting, pair programming, safe AI application"
Building Applications with Vector Databases,Short Course,https://www.deeplearning.ai/short-courses/building-applications-vector-databases/,Beginner,1 Hour,Tim Tully,Learn to create six exciting applications of vector databases and implement them using Pinecone. Build a hybrid search app that combines both text and images for improved multimodal search results. Learn how to build an app that measures and ranks facial similarity.,"Vector databases use embeddings to capture the meaning of data, gauge the similarity between different pairs of vectors, and navigate large datasets to identify the most similar vectors. In the context of large language models, the primary use of vector databases is retrieval augmented generation (RAG), where text embeddings are stored and retrieved for specific queries.  However, the versatility of vector databases extends beyond RAG and makes it possible to build a wide range of applications quickly with minimal coding. In this course, you’ll explore the implementation of six applications using vector databases: Semantic Search: Create a search tool that goes beyond keyword matching, focusing on the meaning of content for efficient text-based searches on a user Q/A dataset.
RAG: Enhance your LLM applications by incorporating content from sources the model wasn’t trained on, like answering questions using the Wikipedia dataset.
Recommender System: Develop a system that combines semantic search and RAG to recommend topics, and demonstrate it with a news article dataset.
Hybrid Search: Build an application that finds items using both images and descriptive text, using an eCommerce dataset as an example.
Facial Similarity: Create an app to compare facial features, using a database of public figures to determine the likeness between them.
Anomaly Detection: Learn how to build an anomaly detection app that identifies unusual patterns in network communication logs.
After taking this course, you’ll be equipped with new ideas for building applications with any vector database.",,"Anyone with beginner Python, basic machine learning and large language models knowledge who wants to learn applications of vector databases.","Vector databases, embeddings, semantic search, retrieval augmented generation (RAG), recommender system"
LLMOps,Short Course,https://www.deeplearning.ai/short-courses/llmops/,Beginner,1 Hour,Erwin Huizenga,"Adapt an open source pipeline that applies supervised fine-tuning on an LLM to better answer user questions. Learn best practices, including versioning your data and your models, and pre-process large datasets inside a data warehouse. Learn responsible AI by outputting safety scores on sub-categories of harmful content.","In this course, you’ll go through the LLMOps pipeline of pre-processing training data for supervised instruction tuning, and adapt a supervised tuning pipeline to train and deploy a custom LLM. This is useful in creating an LLM workflow for your specific application. For example, creating a question-answer chatbot tailored to answer Python coding questions, which you’ll do in this course. Through the course, you’ll go through key steps of creating the LLMOps pipeline: Retrieve and transform training data for supervised fine-tuning of an LLM.
Version your data and tuned models to track your tuning experiments. 
Configure an open-source supervised tuning pipeline and then execute that pipeline to train and then deploy a tuned LLM.
Output and study safety scores to responsibly monitor and filter your LLM application’s behavior.
Try out the tuned and deployed LLM yourself in the classroom!
Tools you’ll practice with include BigQuery data warehouse, the open-source Kubeflow Pipelines, and Google Cloud.",,"Anyone who wants to learn to tune an LLM, and learn to work with and build an LLMOps pipeline.","supervised fine-tuning, LLMOps pipeline, Python, BigQuery data warehouse, Kubeflow Pipelines, Google Cloud"
Advanced Retrieval for AI with Chroma,Short Course,https://www.deeplearning.ai/short-courses/advanced-retrieval-for-ai/,Intermediate,1 Hour,Anton Troynikov,"Learn to recognize when queries are producing poor results.
Learn to use a large language model (LLM) to improve your queries.
Learn to fine-tune your embeddings with user feedback.","Information Retrieval (IR) and Retrieval Augmented Generation (RAG) are only effective if the information retrieved from a database as a result of a query is relevant to the query and its application.
Too often, queries return semantically similar results but don’t answer the question posed. They may also return irrelevant material which can distract the LLM from the correct results.
This course teaches advanced retrieval techniques to improve the relevancy of retrieved results.
The techniques covered include:
Query Expansion: Expanding user queries improves information retrieval by including related concepts and keywords. Utilizing an LLM makes this traditional technique even more effective. Another form of expansion has the LLM suggest a possible answer to the query which is then included in the query.
Cross-encoder reranking: Reranking retrieval results to select the results most relevant to your query improves your results.
Training and utilizing Embedding Adapters: Adding an adapter layer to reshape embeddings can improve retrieval by emphasizing elements relevant to your application.",,Anyone who has intermediate Python knowledge and wants to learn advanced retrieval techniques for retrieving data from their vector database.,"Information Retrieval, Query Expansion, Cross-encoder reranking, Embedding Adapters, LLM"